{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"12WP5DGLXli7X3aWUm1xQJU0STojA7Iwj","authorship_tag":"ABX9TyPkazOXjEBQ4i339j0oML6V"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["### ğŸŸ© CELL 1 â€” Mount Google Drive"],"metadata":{"id":"hwos8jLghutt"}},{"cell_type":"code","source":["# ===============================\n","# CELL 1: MOUNT GOOGLE DRIVE\n","# ===============================\n","# This allows Colab to access files from your Google Drive\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# After mounting:\n","# Your files will be available at:\n","# /content/drive/MyDrive/\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_sjNxEwpkLf8","executionInfo":{"status":"ok","timestamp":1769871702701,"user_tz":-300,"elapsed":71125,"user":{"displayName":"George Leo","userId":"16571523744453624289"}},"outputId":"ab37525a-f10d-420c-a19b-fabf059d4387"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["### ğŸŸ© CELL 2 â€” Import Required Libraries\n"],"metadata":{"id":"ng3g0o9Bh3lM"}},{"cell_type":"code","source":["# ===============================\n","# CELL 2: IMPORT LIBRARIES\n","# ===============================\n","\n","import tensorflow as tf\n","from tensorflow.keras import layers, models\n"],"metadata":{"id":"0eksu33DkMA0","executionInfo":{"status":"ok","timestamp":1769871735486,"user_tz":-300,"elapsed":4781,"user":{"displayName":"George Leo","userId":"16571523744453624289"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["### ğŸŸ© CELL 3 â€” Define Dataset Path"],"metadata":{"id":"xkff7Fhth9Jr"}},{"cell_type":"code","source":["# ===============================\n","# CELL 3: DATASET PATH\n","# ===============================\n","\n","dataset_path = \"/content/drive/MyDrive/cats and dogs\"\n"],"metadata":{"id":"uD2CwIE2kMt8","executionInfo":{"status":"ok","timestamp":1769871799577,"user_tz":-300,"elapsed":43,"user":{"displayName":"George Leo","userId":"16571523744453624289"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["### ğŸŸ© CELL 4 â€” Load Images + Split into Train & Validation"],"metadata":{"id":"QurkOHlBiobb"}},{"cell_type":"code","source":["# ===============================\n","# CELL 4: LOAD DATASET\n","# ===============================\n","# image_dataset_from_directory does ALL of this:\n","# - Reads images\n","# - Resizes them\n","# - Converts them to tensors\n","# - Assigns labels\n","# - Creates batches\n","# - Splits into training & validation\n","\n","train_data = tf.keras.utils.image_dataset_from_directory(\n","    dataset_path,\n","    validation_split=0.2,        # 20% data for validation\n","    subset=\"training\",           # training data\n","    seed=123,                    # ensures same split every time\n","    image_size=(128, 128),       # resize all images\n","    batch_size=32\n",")\n","\n","val_data = tf.keras.utils.image_dataset_from_directory(\n","    dataset_path,\n","    validation_split=0.2,\n","    subset=\"validation\",         # validation data\n","    seed=123,\n","    image_size=(128, 128),\n","    batch_size=32\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"83cqL0sKkNZ8","executionInfo":{"status":"ok","timestamp":1769871833983,"user_tz":-300,"elapsed":738,"user":{"displayName":"George Leo","userId":"16571523744453624289"}},"outputId":"35a1582c-6fd6-4689-a14f-8d8447b71f4f"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1000 files belonging to 2 classes.\n","Using 800 files for training.\n","Found 1000 files belonging to 2 classes.\n","Using 200 files for validation.\n"]}]},{"cell_type":"markdown","source":["### ğŸŸ© CELL 5 â€” Check Class Labels"],"metadata":{"id":"tQTq8CIrjdzG"}},{"cell_type":"code","source":["# ===============================\n","# CELL 5: CHECK CLASS NAMES\n","# ===============================\n","\n","class_names = train_data.class_names\n","print(class_names)\n","\n","# Example output:\n","# ['cats', 'dogs']\n","#\n","# cats  -> label 0\n","# dogs  -> label 1\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x9SSQd3AkPPM","executionInfo":{"status":"ok","timestamp":1769871865479,"user_tz":-300,"elapsed":52,"user":{"displayName":"George Leo","userId":"16571523744453624289"}},"outputId":"db68ebf4-93a9-4703-b006-640842439b65"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["['cats_set', 'dogs_set']\n"]}]},{"cell_type":"markdown","source":["### ğŸŸ© CELL 6 â€” Normalize Images"],"metadata":{"id":"d0Ud7HeCjedO"}},{"cell_type":"code","source":["# ===============================\n","# CELL 6: NORMALIZATION\n","# ===============================\n","# This layer converts pixel values from:\n","# [0, 255] â†’ [0, 1]\n","\n","normalization_layer = layers.Rescaling(1./255)\n","\n","# Apply normalization to each batch\n","train_data = train_data.map(lambda x, y: (normalization_layer(x), y))\n","val_data = val_data.map(lambda x, y: (normalization_layer(x), y))\n"],"metadata":{"id":"TQzJ-jGOkP7s","executionInfo":{"status":"ok","timestamp":1769871897223,"user_tz":-300,"elapsed":63,"user":{"displayName":"George Leo","userId":"16571523744453624289"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["### ğŸŸ© CELL 7 â€” Build CNN Model"],"metadata":{"id":"_NaIzOBnjerx"}},{"cell_type":"code","source":["# ===============================\n","# CELL 7: BUILD CNN MODEL\n","# ===============================\n","\n","model = models.Sequential([\n","\n","    # --------------------------------\n","    # INPUT + CONVOLUTION LAYER 1\n","    # --------------------------------\n","    # - Image enters here\n","    # - 32 kernels of size 3x3 slide over image\n","    # - ReLU applied after convolution\n","\n","    layers.Conv2D(\n","        filters=32,\n","        kernel_size=(3,3),\n","        activation='relu',\n","        input_shape=(128, 128, 3)  # RGB image\n","    ),\n","\n","    # --------------------------------\n","    # POOLING LAYER 1\n","    # --------------------------------\n","    # - Reduces spatial size by half\n","    # - Keeps important features\n","\n","    layers.MaxPooling2D(pool_size=(2,2)),\n","\n","    # --------------------------------\n","    # CONVOLUTION LAYER 2\n","    # --------------------------------\n","    # - Learns more complex features\n","    # - Works on feature maps, not raw pixels\n","\n","    layers.Conv2D(64, (3,3), activation='relu'),\n","\n","    # --------------------------------\n","    # POOLING LAYER 2\n","    # --------------------------------\n","\n","    layers.MaxPooling2D(pool_size=(2,2)),\n","\n","    # --------------------------------\n","    # FLATTEN LAYER\n","    # --------------------------------\n","    # - Converts 2D feature maps â†’ 1D vector\n","    # - Bridge between CNN and ANN\n","\n","    layers.Flatten(),\n","\n","    # --------------------------------\n","    # DENSE (FULLY CONNECTED) LAYER\n","    # --------------------------------\n","    # - Learns combinations of features\n","\n","    layers.Dense(64, activation='relu'),\n","\n","    # --------------------------------\n","    # OUTPUT LAYER\n","    # --------------------------------\n","    # - 2 neurons = 2 classes\n","    # - Softmax outputs probabilities\n","\n","    layers.Dense(2, activation='softmax')\n","])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"36Ww92YRkQks","executionInfo":{"status":"ok","timestamp":1769871947755,"user_tz":-300,"elapsed":34,"user":{"displayName":"George Leo","userId":"16571523744453624289"}},"outputId":"f0260ed2-bec9-405f-c515-9ee6c15655e8"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]}]},{"cell_type":"markdown","source":["### ğŸŸ© CELL 8 â€” Compile Model"],"metadata":{"id":"26Fskutkje4u"}},{"cell_type":"code","source":["# ===============================\n","# CELL 8: COMPILE MODEL\n","# ===============================\n","\n","model.compile(\n","    optimizer='adam',                       # updates weights\n","    loss='sparse_categorical_crossentropy', # for integer labels\n","    metrics=['accuracy']                    # measure performance\n",")\n"],"metadata":{"id":"8FpWyby1kRVM","executionInfo":{"status":"ok","timestamp":1769871963210,"user_tz":-300,"elapsed":44,"user":{"displayName":"George Leo","userId":"16571523744453624289"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["### ğŸŸ© CELL 9 â€” Train the Model"],"metadata":{"id":"x_09XvSaj5mp"}},{"cell_type":"code","source":["# ===============================\n","# CELL 9: TRAIN MODEL\n","# ===============================\n","\n","history = model.fit(\n","    train_data,\n","    epochs=5,                 # number of full passes over data\n","    validation_data=val_data\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HMK_hHkvkRuD","executionInfo":{"status":"ok","timestamp":1769872254712,"user_tz":-300,"elapsed":267677,"user":{"displayName":"George Leo","userId":"16571523744453624289"}},"outputId":"6b405da3-c054-43e9-9b7b-cc6d90f993ec"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 5s/step - accuracy: 0.4926 - loss: 0.8659 - val_accuracy: 0.4750 - val_loss: 0.6921\n","Epoch 2/5\n","\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - accuracy: 0.6179 - loss: 0.6622 - val_accuracy: 0.4550 - val_loss: 0.7264\n","Epoch 3/5\n","\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 941ms/step - accuracy: 0.6672 - loss: 0.5940 - val_accuracy: 0.6250 - val_loss: 0.6980\n","Epoch 4/5\n","\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 945ms/step - accuracy: 0.8338 - loss: 0.3864 - val_accuracy: 0.6750 - val_loss: 0.6468\n","Epoch 5/5\n","\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 926ms/step - accuracy: 0.9064 - loss: 0.2580 - val_accuracy: 0.6650 - val_loss: 0.8215\n"]}]},{"cell_type":"markdown","source":["### ğŸŸ© CELL 10 â€” Check Accuracy on Validation Data"],"metadata":{"id":"spYcOsE6j9kn"}},{"cell_type":"code","source":["# ===============================\n","# CELL 10: EVALUATE MODEL\n","# ===============================\n","\n","model.evaluate(val_data)\n","\n","# Output example:\n","# loss: 0.3\n","# accuracy: 0.90\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sJzvrT59kSQc","executionInfo":{"status":"ok","timestamp":1769872275045,"user_tz":-300,"elapsed":2556,"user":{"displayName":"George Leo","userId":"16571523744453624289"}},"outputId":"9e2c3ec3-698c-40e6-893f-2b837cee38ef"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 225ms/step - accuracy: 0.6711 - loss: 0.8287\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.8214801549911499, 0.6650000214576721]"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":[],"metadata":{"id":"lIesCHZxoj-P"},"execution_count":null,"outputs":[]}]}